---
layout: post
title: "250702_TIL"
date: 2025-07-02 21:00:00 +0900
categories: [크롤링, 데이터 수집, TIL]
tags: [웹 크롤링, Tweepy, Twitter API, requests, BeautifulSoup, robots.txt, 데이터 수집]
---

<style>
  .initial-content, .search-content {
      padding-left: 40px;
      padding-right: 40px;
  }
</style>

<h2>📘 250702_TIL</h2>

---

<h3>1️⃣ 웹 크롤링 기초와 robots.txt 이해</h3>

- **robots.txt란?**  
  웹사이트가 크롤러에게 접근 가능 여부를 알려주는 `텍스트 설정 파일`  
  - 위치: `https://도메인/robots.txt`
  - 주요 명령어  
    - `User-agent`: 어떤 봇을 대상으로 할지 지정  
    - `Disallow`: 접근 차단 경로  
    - `Allow`: 접근 허용 경로  

  예시:
    - User-agent: *
    - Disallow: /private/
    - Allow: /public/

- **크롤링 매너 & 윤리**
- `robots.txt` 확인 → 불법 크롤링 방지
- `User-Agent` 명시 → 기본값이 아닌 브라우저처럼 위장
- `time.sleep()` → 서버 부하 방지 (예: 1초 대기)
- 과도한 요청은 IP 차단, 법적 분쟁 가능성 있음

- **기본 크롤링 코드 예시**
```python
import requests
from bs4 import BeautifulSoup
import time

headers = {'User-Agent': 'Mozilla/5.0'}
url = 'https://example.com'
response = requests.get(url, headers=headers)
time.sleep(1)
soup = BeautifulSoup(response.text, 'html.parser')
```

### 2️⃣ 트위터 API를 활용한 키워드 기반 데이터 수집
- **Tweepy란?**  
  Python에서 Twitter API를 쉽게 다룰 수 있게 해주는 라이브러리로,  
  인증 후 `search_tweets()` 메서드를 통해 키워드 기반 트윗 수집이 가능함.

- **필수 인증키 4종**
  - `consumer_key`
  - `consumer_secret`
  - `access_token`
  - `access_token_secret`

- **오늘 실습 내용 요약**
  - 키워드: `'당근 사기 거래'`
  - 수집 수: 최근 100개의 트윗
  - 수집 항목: 작성 시각, 사용자 계정, 트윗 본문

- **Tweepy 실습 코드 예시**
```
import tweepy

# 인증
consumer_key = 'your_consumer_key'
consumer_secret = 'your_consumer_secret'
access_token = 'your_access_token'
access_token_secret = 'your_access_token_secret'

auth = tweepy.OAuth1UserHandler(consumer_key, consumer_secret, access_token, access_token_secret)
api = tweepy.API(auth)

# 키워드 기반 트윗 수집
keyword = '키워드 입력'
count = 100
tweets = tweepy.Cursor(api.search_tweets, q=keyword, lang="ko", since="2023-01-01").items(count)

tweet_data = []
for tweet in tweets:
    tweet_data.append([tweet.created_at, tweet.user.screen_name, tweet.text])
```

- **유의사항**
  - rate limit 존재: 호출 제한 있으므로 수집량 관리 필수
  - 데이터는 JSON 구조 → 필요한 필드 파악 후 가공 필요
  - 검색 API는 오래된 트윗까지 수집되지 않음

